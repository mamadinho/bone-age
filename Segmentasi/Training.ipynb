{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.ndimage.morphology import binary_dilation\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a28be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b7\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 1, 512, 512).requires_grad_(True)\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df74f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(y, params=dict(list(model.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a9327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoneAgeSegmentationDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, mean=0.5, std=0.25):\n",
    "        super(BoneAgeSegmentationDataset, self).__init__()\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.resize = A.Compose([\n",
    "            #     A.ChannelDropout(p=0.3),\n",
    "                A.Resize(height=512, width=512)\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx, raw=False):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = cv2.imread(row['input'], cv2.IMREAD_UNCHANGED)\n",
    "        mask = cv2.imread(row['label'], cv2.IMREAD_GRAYSCALE)\n",
    "        resized = self.resize(image=img, mask=mask)\n",
    "        img, mask = resized['image'], resized['mask']\n",
    "        if raw:\n",
    "            return img, mask\n",
    "        \n",
    "        if self.transform:\n",
    "#             img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img, mask = augmented['image'], augmented['mask']\n",
    "        \n",
    "        img = T.functional.to_tensor(img)\n",
    "        mask = mask // 255\n",
    "        mask = torch.Tensor(mask)\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beeed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sorted(os.listdir('input/'))\n",
    "labels = os.listdir('labels/')\n",
    "labels = sorted(labels, key=lambda x: int(os.path.splitext(x)[0].split(\"-\")[1]))\n",
    "\n",
    "df = pd.DataFrame({'input': inputs, 'label': labels}, columns=[\"input\", \"label\"])\n",
    "df.input = 'input/' + df.input\n",
    "df.label = 'labels/' + df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86939afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "test_df, valid_df = train_test_split(test_df, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c45731",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "#     A.ChannelDropout(p=0.3),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.ColorJitter(p=0.3),\n",
    "    A.Resize(height=512, width=512)\n",
    "])\n",
    "\n",
    "train_dataset = BoneAgeSegmentationDataset(train_df, transform)\n",
    "valid_dataset = BoneAgeSegmentationDataset(valid_df)\n",
    "test_dataset = BoneAgeSegmentationDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f669116",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "n_examples = 4\n",
    "\n",
    "fig, axs = plt.subplots(n_examples, 3, figsize=(20, n_examples*7), constrained_layout=True)\n",
    "i = 0\n",
    "for ax in axs:\n",
    "    while True:\n",
    "        image, mask = train_dataset.__getitem__(i, raw=True)\n",
    "#         image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "        i += 1\n",
    "#         if np.any(mask): \n",
    "        ax[0].set_title(\"MRI images\")\n",
    "        ax[0].imshow(image, cmap='gray')\n",
    "        ax[1].set_title(\"Highlited abnormality\")\n",
    "        ax[1].imshow(np.where(mask==0, 0, image), cmap='gray')\n",
    "        ax[2].imshow(mask, cmap='gray')\n",
    "        ax[2].set_title(\"Abnormality mask\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b46d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    \"\"\"\n",
    "    Stops training when loss stops decreasing in a PyTorch module.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience:int = 6, min_delta: float = 0, weights_path: str = 'weights.pt'):\n",
    "        \"\"\"\n",
    "        :param patience: number of epochs of non-decreasing loss before stopping\n",
    "        :param min_delta: minimum difference between best and new loss that is considered\n",
    "            an improvement\n",
    "        :paran weights_path: Path to the file that should store the model's weights\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.weights_path = weights_path\n",
    "\n",
    "    def __call__(self, val_loss: float, model: torch.nn.Module):\n",
    "        if self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            torch.save(model.state_dict(), self.weights_path)\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def load_weights(self, model: torch.nn.Module):\n",
    "        \"\"\"\n",
    "        Loads weights of the best model.\n",
    "        :param model: model to which the weigths should be loaded\n",
    "        \"\"\"\n",
    "        return model.load_state_dict(torch.load(self.weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0eb9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_pytorch(predictions: torch.Tensor, labels: torch.Tensor, e: float = 1e-7):\n",
    "    \"\"\"Calculates Intersection over Union for a tensor of predictions\"\"\"\n",
    "    predictions = torch.where(predictions > 0.5, 1, 0)\n",
    "    labels = labels.byte()\n",
    "    \n",
    "    intersection = (predictions & labels).float().sum((1, 2))\n",
    "    union = (predictions | labels).float().sum((1, 2))\n",
    "    \n",
    "    iou = (intersection + e) / (union + e)\n",
    "    return iou\n",
    "\n",
    "def dice_pytorch(predictions: torch.Tensor, labels: torch.Tensor, e: float = 1e-7):\n",
    "    \"\"\"Calculates Dice coefficient for a tensor of predictions\"\"\"\n",
    "    predictions = torch.where(predictions > 0.5, 1, 0)\n",
    "    labels = labels.byte()\n",
    "    \n",
    "    intersection = (predictions & labels).float().sum((1, 2))\n",
    "    return ((2 * intersection) + e) / (predictions.float().sum((1, 2)) + labels.float().sum((1, 2)) + e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCE_dice(output, target, alpha=0.01):\n",
    "    bce = torch.nn.functional.binary_cross_entropy(output, target)\n",
    "    soft_dice = 1 - dice_pytorch(output, target).mean()\n",
    "    return bce + alpha * soft_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b79936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.FPN(\n",
    "    encoder_name=\"efficientnet-b7\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    "    activation='sigmoid',\n",
    ")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1954dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, model, train_loader, valid_loader, optimizer, loss_fn, lr_scheduler):\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_IoU': [], 'val_dice': []}\n",
    "    early_stopping = EarlyStopping(patience=7)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        running_loss = 0\n",
    "        model.train()\n",
    "        for i, data in enumerate(tqdm(train_loader)):\n",
    "            img, mask = data\n",
    "            img, mask = img.to(device), mask.to(device)\n",
    "            predictions = model(img)\n",
    "            predictions = predictions.squeeze(1)\n",
    "            loss = loss_fn(predictions, mask)\n",
    "            running_loss += loss.item() * img.size(0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            running_IoU = 0\n",
    "            running_dice = 0\n",
    "            running_valid_loss = 0\n",
    "            for i, data in enumerate(valid_loader):\n",
    "                img, mask = data\n",
    "                img, mask = img.to(device), mask.to(device)\n",
    "                predictions = model(img)\n",
    "                predictions = predictions.squeeze(1)\n",
    "                running_dice += dice_pytorch(predictions, mask).sum().item()\n",
    "                running_IoU += iou_pytorch(predictions, mask).sum().item()\n",
    "                loss = loss_fn(predictions, mask)\n",
    "                running_valid_loss += loss.item() * img.size(0)\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        val_loss = running_valid_loss / len(valid_loader.dataset)\n",
    "        val_dice = running_dice / len(valid_loader.dataset)\n",
    "        val_IoU = running_IoU / len(valid_loader.dataset)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_IoU'].append(val_IoU)\n",
    "        history['val_dice'].append(val_dice)\n",
    "        print(f'Epoch: {epoch}/{epochs} | Training loss: {train_loss} | Validation loss: {val_loss} | Validation Mean IoU: {val_IoU} '\n",
    "         f'| Validation Dice coefficient: {val_dice}')\n",
    "        \n",
    "        lr_scheduler.step(val_loss)\n",
    "        if early_stopping(val_loss, model):\n",
    "            early_stopping.load_weights(model)\n",
    "            break\n",
    "    model.eval()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0aafc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_fn = BCE_dice\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer=optimizer, patience=2,factor=0.2)\n",
    "\n",
    "history = training_loop(epochs, model, train_loader, valid_loader, optimizer, loss_fn, lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765cd49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(history['train_loss'], label='Training', color='red')\n",
    "plt.plot(history['val_loss'], label='Validation', color='green')\n",
    "plt.ylim(0, 0.3)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (BCE Dice)')\n",
    "plt.title('Training Performance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.ylim(0.7, 1)\n",
    "plt.plot(history['val_IoU'], label='Validation Mean IoU', color='blue')\n",
    "plt.plot(history['val_dice'], label='Validation Dice', color='orange')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Mean IoU and Dice in Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44108454",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    running_IoU = 0\n",
    "    running_dice = 0\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(test_loader):\n",
    "        img, mask = data\n",
    "        img, mask = img.to(device), mask.to(device)\n",
    "        predictions = model(img)\n",
    "        predictions = predictions.squeeze(1)\n",
    "        running_dice += dice_pytorch(predictions, mask).sum().item()\n",
    "        running_IoU += iou_pytorch(predictions, mask).sum().item()\n",
    "        loss = loss_fn(predictions, mask)\n",
    "        running_loss += loss.item() * img.size(0)\n",
    "    loss = running_loss / len(test_dataset)\n",
    "    dice = running_dice / len(test_dataset)\n",
    "    IoU = running_IoU / len(test_dataset)\n",
    "    \n",
    "    print(f'Tests: loss: {loss} | Mean IoU: {IoU} | Dice coefficient: {dice}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f6e6fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "width = 3\n",
    "columns = 2 \n",
    "n_examples = columns * width\n",
    "\n",
    "fig, axs = plt.subplots(columns, width, figsize=(4*width , 4*columns), constrained_layout=True)\n",
    "red_patch = mpatches.Patch(color='red', label='The red data')\n",
    "fig.legend(loc='upper right',handles=[\n",
    "    mpatches.Patch(color='red', label='Ground truth'),\n",
    "    mpatches.Patch(color='green', label='Predicted abnormality')])\n",
    "i = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        image, mask = data\n",
    "        mask = mask[0]\n",
    "        if not mask.byte().any():\n",
    "            continue\n",
    "        image = image.to(device)\n",
    "        prediction = model(image).to('cpu')[0][0]\n",
    "        prediction = torch.where(prediction > 0.5, 1, 0)\n",
    "        prediction_edges = prediction - binary_dilation(prediction)\n",
    "        ground_truth = mask - binary_dilation(mask)\n",
    "        image = cv2.cvtColor(image[0].to('cpu').permute(1, 2, 0).numpy(),cv2.COLOR_GRAY2RGB)\n",
    "#         print(prediction_edges.bool().shape)\n",
    "        image[ground_truth.bool(), :] = [1, 0, 0]\n",
    "        image[prediction_edges.bool(), :] = [0, 1, 0]\n",
    "        axs[i//width][i%width].imshow(image)\n",
    "        if n_examples == i + 1:\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de38cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "~prediction_edges.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a9d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
